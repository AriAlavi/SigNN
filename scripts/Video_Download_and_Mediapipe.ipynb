{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Video Download and Mediapipe",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fp5kDhCnQ3R8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d176d407-c477-4a22-f4bf-c2f487862bf5"
      },
      "source": [
        "import os\n",
        "import json\n",
        "from os.path import exists, join, basename, splitext\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "class GoogleDriveDatabase:\n",
        "  def __init__(self, drive, DATABASE_GID:str):\n",
        "    assert isinstance(DATABASE_GID, str)\n",
        "    self.folders = {}\n",
        "    self.drive = drive\n",
        "    self.database_gid = DATABASE_GID\n",
        "    folder_list = drive.ListFile({'q': \"'{}' in parents and trashed=false\".format(DATABASE_GID)}).GetList()\n",
        "    self.update_folders(drive)\n",
        "    print(\"{} folders loaded\".format(len(self.folders.keys())))\n",
        "  def update_folders(self,drive):\n",
        "    folder_list = drive.ListFile({'q': \"'{}' in parents and trashed=false\".format(self.database_gid)}).GetList()\n",
        "    self.folders = {}\n",
        "    for file in folder_list:\n",
        "      if file['mimeType'] == \"application/vnd.google-apps.folder\":\n",
        "        self.folders[file['title']] = file['id']\n",
        "    return self.folders\n",
        "\n",
        "  def upload(self, filename, character, fileType):\n",
        "    assert isinstance(filename, str)\n",
        "    assert isinstance(character, str)\n",
        "    assert isinstance(fileType, str)\n",
        "    FILETYPE_MIME_MAP = {\n",
        "        \"jpeg\" : \"image/jpeg\",\n",
        "        \"json\" : \"application/json\",\n",
        "        \"zip\" : \"application/zip\",\n",
        "        \"avi\" : \"video/avi\"\n",
        "    }\n",
        "    assert fileType in FILETYPE_MIME_MAP.keys(), \"fileType must be one of the following: {}\".format(fileType)\n",
        "    assert os.path.isfile(filename), \"{} does not exist as a file\".format(filename)\n",
        "    assert self.checkFolder(character), \"{} is not a valid character. Pick from list: \\n{}\".format(character, tuple(self.folders.keys()))\n",
        "    file = self.drive.CreateFile({\n",
        "        \"title\" :  os.path.split(filename)[1],\n",
        "        \"mimeType\" : FILETYPE_MIME_MAP[fileType],\n",
        "        \"parents\" : [{\"id\" : self.folders[character]}]\n",
        "    })\n",
        "    file.SetContentFile(filename)\n",
        "    file.Upload()\n",
        "    print(\"uploaded {}\".format(filename))\n",
        "\n",
        "  @staticmethod\n",
        "  def allImagesToJPG(fileName) -> str:\n",
        "    assert isinstance(fileName, str)\n",
        "    assert any(extension for extension in GoogleDriveDatabase.VIDEO_EXTENSIONS()), \"{} is not a valid image\".format(fileName)\n",
        "    if \".avi\" in fileName:\n",
        "      return fileName\n",
        "    return fileName.split(\".\")[0] + \".avi\"\n",
        "    \n",
        "  @staticmethod\n",
        "  def VIDEO_EXTENSIONS() -> list:\n",
        "    return [\".avi\", \".mp4\"]\n",
        "\n",
        "  @staticmethod\n",
        "  def FILE_EXTENSIONS() -> list:\n",
        "    return [\".jpg\", \".jpeg\", \".png\", \".zip\", \".json\"]\n",
        "\n",
        "  def getFiles(self, character) -> list:\n",
        "    return [\n",
        "      x for x in self.drive.ListFile({'q': \"'{}' in parents and trashed=false\".format(self.folders[character])}).GetList()\n",
        "      if x['mimeType'] != \"application/vnd.google-apps.folder\" \n",
        "    ]\n",
        "  def download_file_name(self, file_name):\n",
        "      if not any(extension in file_name for extension in GoogleDriveDatabase.FILE_EXTENSIONS() + GoogleDriveDatabase.VIDEO_EXTENSIONS()):\n",
        "        file_name += \".avi\"\n",
        "      return GoogleDriveDatabase.allImagesToJPG(file_name)\n",
        "\n",
        "  def download_file(self, file, folder:str, **kwargs) -> str:\n",
        "      check_already_exist = kwargs.get(\"check_local\", False)\n",
        "      file_name = os.path.join(folder, file['title'])\n",
        "      file_name = self.download_file_name(file_name)\n",
        "      if check_already_exist:\n",
        "        local_files = [os.path.join(folder, file) for file in os.listdir(folder)]\n",
        "        if file_name in local_files:\n",
        "          return file_name\n",
        "      file.GetContentFile(file_name)\n",
        "      print(\"downloaded\", file_name)\n",
        "      return file_name\n",
        "\n",
        "  def download(self, character:str,folder:str):\n",
        "    file_list = self.getFiles(character)\n",
        "    os.makedirs(folder, exist_ok=True)\n",
        "    returnlist = []\n",
        "    \n",
        "    for file in file_list:\n",
        "      returnlist.append(self.download_file(file, folder, check_local=True))\n",
        "    return tuple(returnlist)\n",
        "\n",
        "  def checkFolder(self, name):\n",
        "    assert isinstance(name, str)\n",
        "    return name in self.folders.keys()\n",
        "\n",
        "  def createFolder(self, name, exist_ok=True):\n",
        "    if self.checkFolder(name):\n",
        "      if exist_ok:\n",
        "        return True\n",
        "      raise Exception(\"Folder {} already exists\".format(name))\n",
        "    self.drive.CreateFile({\n",
        "        \"title\" : name,\n",
        "        \"mimeType\" : \"application/vnd.google-apps.folder\",\n",
        "        \"parents\" : [{\"id\" : self.database_gid}]\n",
        "    }).Upload()\n",
        "  def move_file(self, file_obj, newFolder):\n",
        "    assert isinstance(newFolder, str)\n",
        "    assert self.checkFolder(newFolder)\n",
        "    files = self.drive.auth.service.files()\n",
        "    file = files.get(fileId=file_obj['id'], fields ='parents').execute()\n",
        "    prev_parents = ','.join(p['id'] for p in file.get('parents'))\n",
        "    file = files.update(\n",
        "        fileId = file_obj['id'],\n",
        "        addParents = self.folders[newFolder],\n",
        "        removeParents = prev_parents,\n",
        "        fields = 'id, parents',\n",
        "    ).execute()\n",
        "    return file\n",
        "  def trash(self, file_obj):\n",
        "    self.move_file(file_obj, \"TRASH\")\n",
        "    print(\"Sent {} to trash\".format(file_obj['title']))\n",
        "\n",
        "auth.authenticate_user() # Google auth stuff, make sure to sign in with your ucsb account\n",
        "gauth = GoogleAuth() # Google auth stuff\n",
        "gauth.credentials = GoogleCredentials.get_application_default() # Google auth stuff\n",
        "drive = GoogleDrive(gauth) # Google auth stuff\n",
        "\n",
        "DOWNLOAD_DATABASE = \"14HLz4WqhRCRfFfNHSOrnOfUWewpZe2oP\"\n",
        "UPLOAD_DATABASE = \"1Z9KA09PAnl0WyEgDLML83EghyqYK1vOe\"\n",
        "download_database = GoogleDriveDatabase(drive, DOWNLOAD_DATABASE)\n",
        "upload_database = GoogleDriveDatabase(drive,UPLOAD_DATABASE)\n",
        "CHARACTERS = (\"J\", \"Z\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4 folders loaded\n",
            "3 folders loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQmLT7HX15nQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        },
        "outputId": "90d82511-5502-4df1-f569-13cc00de5459"
      },
      "source": [
        "import os\n",
        "import json\n",
        "from os.path import exists, join, basename, splitext\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Compile mediapipe\n",
        "git_repo_url = 'https://github.com/AriAlavi/SigNN.git'\n",
        "project_name = splitext(basename(git_repo_url))[0]\n",
        "if not exists(project_name):\n",
        "  print(\"Does not yet exist\")\n",
        "  !wget -q https://cmake.org/files/v3.13/cmake-3.13.0-Linux-x86_64.tar.gz\n",
        "  !tar xfz cmake-3.13.0-Linux-x86_64.tar.gz --strip-components=1 -C /usr/local\n",
        "  !git clone -q --depth 1 $git_repo_url\n",
        "  !sudo apt install curl\n",
        "  !curl https://bazel.build/bazel-release.pub.gpg | sudo apt-key add -\n",
        "  !echo \"deb [arch=amd64] https://storage.googleapis.com/bazel-apt stable jdk1.8\" | sudo tee /etc/apt/sources.list.d/bazel.list\n",
        "  !sudo apt update && sudo apt install bazel-3.3.0\n",
        "  !sudo apt-get install libopencv-core-dev libopencv-highgui-dev \\\n",
        "                        libopencv-calib3d-dev libopencv-features2d-dev \\\n",
        "                        libopencv-imgproc-dev libopencv-video-dev\n",
        "  !cd {project_name} && git fetch --all\n",
        "  !cd {project_name} && git checkout 9941e9cf9a48eae52ed4e43420eb8cafcd3998f5\n",
        "  !cd {project_name} && git pull\n",
        "  !cd {project_name} && bazel-3.3.0 build -c opt --define MEDIAPIPE_DISABLE_GPU=1 mediapipe/examples/desktop/multi_hand_tracking:multi_hand_tracking_cpu \n",
        "else:\n",
        "  print(\"Already exists\")\n",
        "  !git config --global user.email \"none@gmail.com\"\n",
        "  !git config --global user.name \"Google colab\"\n",
        "  !cd {project_name} && git stash\n",
        "  !cd {project_name} && git fetch --all\n",
        "  !cd {project_name} && git checkout 9941e9cf9a48eae52ed4e43420eb8cafcd3998f5\n",
        "  !cd {project_name} && git pull\n",
        "  !cd {project_name} && bazel-3.3.0 build -c opt --define MEDIAPIPE_DISABLE_GPU=1 mediapipe/examples/desktop/multi_hand_tracking:multi_hand_tracking_cpu "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Already exists\n",
            "Saved working directory and index state WIP on master: 5012415 Added more mediapipe calculators for signn\n",
            "Fetching origin\n",
            "fatal: reference is not a tree: 9941e9cf9a48eae52ed4e43420eb8cafcd3998f5\n",
            "Already up to date.\n",
            "\u001b[35mWARNING: \u001b[0mDownload from https://mirror.bazel.build/github.com/tensorflow/tensorflow/archive/7c09d15f9fcc14343343c247ebf5b8e0afe3e4aa.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\n",
            "\u001b[32mAnalyzing:\u001b[0m target //mediapipe/examples/desktop/multi_hand_tracking:multi_hand_\\\n",
            "\u001b[35mWARNING: \u001b[0mDownload from http://mirror.tensorflow.org/github.com/bazelbuild/rules_closure/archive/cf1e44edb908e9616030cc83d085989b8e6cd6df.tar.gz failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\n",
            "\u001b[32mAnalyzing:\u001b[0m target //mediapipe/examples/desktop/multi_hand_tracking:multi_hand_\\\n",
            "\u001b[32mAnalyzing:\u001b[0m target //mediapipe/examples/desktop/multi_hand_tracking:multi_hand_\\\n",
            "\u001b[33mDEBUG: \u001b[0mRule 'rules_cc' indicated that a canonical reproducible form can be obtained by modifying arguments sha256 = \"2a34fa56d923f774409d23720e60ddf6536e88622d000e6925f7cebbad65e281\"\n",
            "\u001b[32mAnalyzing:\u001b[0m target //mediapipe/examples/desktop/multi_hand_tracking:multi_hand_\\\n",
            "\u001b[33mDEBUG: \u001b[0mRepository rules_cc instantiated at:\n",
            "  no stack (--record_rule_instantiation_callstack not enabled)\n",
            "Repository rule http_archive defined at:\n",
            "  /root/.cache/bazel/_bazel_root/6b05d56d57241dcd7692847de0d8c695/external/bazel_tools/tools/build_defs/repo/http.bzl:336:31: in <toplevel>\n",
            "\u001b[32mAnalyzing:\u001b[0m target //mediapipe/examples/desktop/multi_hand_tracking:multi_hand_\\\n",
            "\u001b[35mWARNING: \u001b[0mDownload from https://storage.googleapis.com/mirror.tensorflow.org/github.com/google/XNNPACK/archive/5cb16e7ace0fcdcab164af01620a606ba828a3be.zip failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\n",
            "\u001b[32mAnalyzing:\u001b[0m target //mediapipe/examples/desktop/multi_hand_tracking:multi_hand_\\\n",
            "\u001b[35mWARNING: \u001b[0mDownload from https://mirror.bazel.build/github.com/Maratyszcza/FP16/archive/3c54eacb74f6f5e39077300c5564156c424d77ba.zip failed: class com.google.devtools.build.lib.bazel.repository.downloader.UnrecoverableHttpException GET returned 404 Not Found\n",
            "\u001b[32mAnalyzing:\u001b[0m target //mediapipe/examples/desktop/multi_hand_tracking:multi_hand_\\\n",
            "\u001b[35mWARNING: \u001b[0m/root/.cache/bazel/_bazel_root/6b05d56d57241dcd7692847de0d8c695/external/org_tensorflow/tensorflow/core/BUILD:1757:11: in linkstatic attribute of cc_library rule @org_tensorflow//tensorflow/core:lib_internal: setting 'linkstatic=1' is recommended if there are no object files. Since this rule was created by the macro 'cc_library', the error might have been caused by the macro implementation\n",
            "\u001b[32mAnalyzing:\u001b[0m target //mediapipe/examples/desktop/multi_hand_tracking:multi_hand_\\\n",
            "\u001b[35mWARNING: \u001b[0m/root/.cache/bazel/_bazel_root/6b05d56d57241dcd7692847de0d8c695/external/org_tensorflow/tensorflow/core/BUILD:2202:16: in linkstatic attribute of cc_library rule @org_tensorflow//tensorflow/core:framework_internal: setting 'linkstatic=1' is recommended if there are no object files. Since this rule was created by the macro 'tf_cuda_library', the error might have been caused by the macro implementation\n",
            "\u001b[32mAnalyzing:\u001b[0m target //mediapipe/examples/desktop/multi_hand_tracking:multi_hand_\\\n",
            "\u001b[32mINFO: \u001b[0mAnalyzed target //mediapipe/examples/desktop/multi_hand_tracking:multi_hand_tracking_cpu (0 packages loaded, 0 targets configured).\n",
            "\u001b[32mINFO: \u001b[0mFound 1 target...\n",
            "Target //mediapipe/examples/desktop/multi_hand_tracking:multi_hand_tracking_cpu up-to-date:\n",
            "  bazel-bin/mediapipe/examples/desktop/multi_hand_tracking/multi_hand_tracking_cpu\n",
            "\u001b[32mINFO: \u001b[0mElapsed time: 0.627s, Critical Path: 0.00s\n",
            "\u001b[32mINFO: \u001b[0m0 processes.\n",
            "\u001b[32mINFO:\u001b[0m Build completed successfully, 1 total action\n",
            "\u001b[0m"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW2QIKDRIBtS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "97081359-2ff6-4a5f-d12c-c2002ce4216f"
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from datetime import datetime\n",
        "from random import randint\n",
        "\n",
        "\n",
        "\n",
        "import uuid\n",
        "import os\n",
        "import time\n",
        "\n",
        "\n",
        "  \n",
        "def runMediapipe(input_video):\n",
        "  assert os.path.isfile(input_video), \"{} does not exist\".format(input_video)\n",
        "  # input_video = input_video.encode()\n",
        "  call = \"cd SigNN && sudo GLOG_logtostderr=0 bazel-bin/mediapipe/examples/desktop/multi_hand_tracking/multi_hand_tracking_cpu --calculator_graph_config_file=mediapipe/graphs/hand_tracking/multi_hand_tracking_desktop_logger.pbtxt --input_video_path={} --render_video=false\".format(input_video)\n",
        "  os.system(call)\n",
        "\n",
        "def modifyMediapipeLoggerOutput(path, filename, mediapipe_directory):\n",
        "  assert isinstance(path, str)\n",
        "  assert isinstance(filename, str)\n",
        "  assert filename.split(\".\")[-1] == \"json\"\n",
        "  assert isinstance(mediapipe_directory, str)\n",
        "  os.makedirs(path, exist_ok=True)\n",
        "  pbtxt_name = os.path.join(mediapipe_directory, \"mediapipe/graphs/hand_tracking/multi_hand_tracking_desktop_logger.pbtxt\")\n",
        "  pbtxt_file = open(pbtxt_name, \"r+b\")\n",
        "  pbtxt_content = pbtxt_file.readlines()\n",
        "  line_count = 0\n",
        "  for line in pbtxt_content:\n",
        "    if \"CoordinateLoggerCalculatorOptions\" in str(line):\n",
        "      pbtxt_content[line_count + 2] = '      logger_path: \"{}\"\\n'.format(path).encode()\n",
        "      pbtxt_content[line_count + 3] = '      filename: \"{}\"\\n'.format(filename).encode()\n",
        "      break\n",
        "    line_count += 1\n",
        "  pbtxt_file.seek(0)\n",
        "  pbtxt_file.truncate()\n",
        "  pbtxt_file.write(''.join([x.decode() for x in pbtxt_content]).encode())\n",
        "  pbtxt_file.close()\n",
        "\n",
        "class InvalidMediapipeOutput(Exception):\n",
        "  pass\n",
        "\n",
        "strip_name = lambda x: x.split(\"/\")[-1].split(\".\")[0] # Function to remove extensions (i.e. .mp4 .avi) from filenames\n",
        "\n",
        "def setupMediapipe(json_name, output_directory):\n",
        "  assert \".json\" in json_name\n",
        "  print(\"Setting mediapipe logger output\")\n",
        "  modifyMediapipeLoggerOutput(output_directory, json_name, \"/content/SigNN/\")\n",
        "\n",
        "def Mediapipe(input_directory, video_fullname, output_directory):\n",
        "  video_name = strip_name(video_fullname)\n",
        "  os.makedirs(output_directory, exist_ok=True)\n",
        "  video_path = os.path.join(input_directory, video_fullname)\n",
        "  json_name = video_name + \".json\"\n",
        "  OUTPUT_FILE = os.path.join(output_directory, json_name)\n",
        "  setupMediapipe(json_name, output_directory)\n",
        "  print(\"Running mediapipe on {}\".format(video_path))\n",
        "  runMediapipe(video_path)\n",
        "  return OUTPUT_FILE\n",
        "\n",
        "\n",
        "\n",
        "# def download_characters(): # Only downloads characters\n",
        "#   BASE_DIR = \"images/\"\n",
        "#   results = {}\n",
        "#   for c in CHARACTERS:\n",
        "#     results[c] = download_database.download(c, os.path.join(BASE_DIR, c + \"/\"))\n",
        "#     print(\"{} pictures downloaded for {}\".format(len(results[c]), c))\n",
        "#   return results\n",
        "    \n",
        "def DownloadVideosAndUploadJson(character, max_char):\n",
        "  assert isinstance(character, str)\n",
        "  assert isinstance(max_char, int)\n",
        "\n",
        "  BASE_VIDEOS_DIR = \"/content/videos/\"\n",
        "  BASE_JSON_DIR = \"/content/json/\"\n",
        "\n",
        "  INPUT_DIRECTORY = os.path.join(BASE_VIDEOS_DIR, character)\n",
        "  OUTPUT_DIRECTORY = os.path.join(BASE_JSON_DIR, character)\n",
        " \n",
        "  already_analyzed_names = set() # Names of all already analyzed items\n",
        "  videos_to_analyze = [] # Videos that yet do not have a json file\n",
        "  videos_to_analyze_names = [] # Names of videos that yet do not have a json file\n",
        "  BASE_FOLDER = \"videos/\" # Directory of where all videos are\n",
        "  character_folder = os.path.join(BASE_FOLDER, character + \"/\") # Folder in which the videos for this character are in (i.e. videos/J)\n",
        "  os.makedirs(character_folder, exist_ok=True) # Make the character folder if it doesn't exist\n",
        "  character_jsons_original = upload_database.getFiles(character) # All .json files created for this character\n",
        "  character_jsons_names = [strip_name(x['title']) for x in character_jsons_original] # Name of all .json files already created for this character\n",
        "  video_references = download_database.getFiles(character) # All current videos for this character\n",
        "  video_reference_names = [strip_name(x['title']) for x in video_references] # Name of all videos\n",
        "  print(\"There are {} videos for character {}\".format(len(video_references), character))\n",
        "  print(\"There are {} json files already made for character {}\".format(len(character_jsons_names), character))\n",
        "  for json_original in character_jsons_original: # For every json file on the google drive...\n",
        "    if strip_name(json_original['title']) not in video_reference_names: # ...if the json file is not in the list of videos...\n",
        "      print(\"{} deleted because no video was found to relate to it\".format(json_original['title']))\n",
        "      upload_database.trash(json_original) # ...then delete the file\n",
        "\n",
        "  while len(video_references) > 0 and max_char > 0: # For every video on google drive...\n",
        "    gauth.Refresh()\n",
        "    video = video_references.pop(randint(0, len(video_references)-1))\n",
        "    video_name = strip_name(video['title'])\n",
        "    video_fullname = video['title']\n",
        "    if video_name in character_jsons_names: # ...if that video already has a json uploaded...\n",
        "      already_analyzed_names.add(download_database.download_file_name(video['title'])) # ...add its name to the list of already analyzed video\n",
        "    else:\n",
        "      video_to_analyze = download_database.download_file(video, character_folder, check_local=True)\n",
        "      json_path = Mediapipe(INPUT_DIRECTORY, video_fullname, OUTPUT_DIRECTORY)\n",
        "      time.sleep(1)\n",
        "      upload_database.upload(json_path, character, \"json\")\n",
        "      video_path = os.path.join(INPUT_DIRECTORY, video_fullname)\n",
        "      os.remove(video_path)\n",
        "      os.remove(json_path)\n",
        "      max_char -= 1\n",
        "\n",
        "  if len(video_references) > 0:\n",
        "    return False # Not Complete\n",
        "  print(\"{} complete\".format(character))\n",
        "  return True # Complete\n",
        "\n",
        "for character in CHARACTERS:\n",
        "  while not DownloadVideosAndUploadJson(character, 5):\n",
        "    gauth.Refresh()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 462 videos for character J\n",
            "There are 451 json files already made for character J\n",
            "downloaded videos/J/J_09-01-2020_20_48_04.avi\n",
            "Setting mediapipe logger output\n",
            "Running mediapipe on /content/videos/J/J_09-01-2020_20_48_04.avi\n",
            "uploaded /content/json/J/J_09-01-2020_20_48_04.json\n",
            "downloaded videos/J/J_09-02-2020_08_54_25.avi\n",
            "Setting mediapipe logger output\n",
            "Running mediapipe on /content/videos/J/J_09-02-2020_08_54_25.avi\n",
            "uploaded /content/json/J/J_09-02-2020_08_54_25.json\n",
            "downloaded videos/J/J_09-06-2020_08_38_57.avi\n",
            "Setting mediapipe logger output\n",
            "Running mediapipe on /content/videos/J/J_09-06-2020_08_38_57.avi\n",
            "uploaded /content/json/J/J_09-06-2020_08_38_57.json\n",
            "downloaded videos/J/J_07-30-2020_22_08_58.avi\n",
            "Setting mediapipe logger output\n",
            "Running mediapipe on /content/videos/J/J_07-30-2020_22_08_58.avi\n",
            "uploaded /content/json/J/J_07-30-2020_22_08_58.json\n",
            "downloaded videos/J/J_09-06-2020_08_21_58.avi\n",
            "Setting mediapipe logger output\n",
            "Running mediapipe on /content/videos/J/J_09-06-2020_08_21_58.avi\n",
            "uploaded /content/json/J/J_09-06-2020_08_21_58.json\n",
            "260 references and 0 characters\n",
            "There are 462 videos for character J\n",
            "There are 458 json files already made for character J\n",
            "downloaded videos/J/J_09-02-2020_11_47_30.avi\n",
            "Setting mediapipe logger output\n",
            "Running mediapipe on /content/videos/J/J_09-02-2020_11_47_30.avi\n",
            "uploaded /content/json/J/J_09-02-2020_11_47_30.json\n",
            "downloaded videos/J/J_09-06-2020_08_21_03.avi\n",
            "Setting mediapipe logger output\n",
            "Running mediapipe on /content/videos/J/J_09-06-2020_08_21_03.avi\n",
            "uploaded /content/json/J/J_09-06-2020_08_21_03.json\n",
            "downloaded videos/J/J_09-02-2020_08_50_32.avi\n",
            "Setting mediapipe logger output\n",
            "Running mediapipe on /content/videos/J/J_09-02-2020_08_50_32.avi\n",
            "uploaded /content/json/J/J_09-02-2020_08_50_32.json\n",
            "downloaded videos/J/J_09-06-2020_08_26_26.avi\n",
            "Setting mediapipe logger output\n",
            "Running mediapipe on /content/videos/J/J_09-06-2020_08_26_26.avi\n",
            "uploaded /content/json/J/J_09-06-2020_08_26_26.json\n",
            "downloaded videos/J/J_08-03-2020_15_16_56.avi\n",
            "Setting mediapipe logger output\n",
            "Running mediapipe on /content/videos/J/J_08-03-2020_15_16_56.avi\n",
            "uploaded /content/json/J/J_08-03-2020_15_16_56.json\n",
            "131 references and 0 characters\n",
            "There are 462 videos for character J\n",
            "There are 464 json files already made for character J\n",
            "downloaded videos/J/J_08-28-2020_14_14_09.avi\n",
            "Setting mediapipe logger output\n",
            "Running mediapipe on /content/videos/J/J_08-28-2020_14_14_09.avi\n",
            "uploaded /content/json/J/J_08-28-2020_14_14_09.json\n",
            "0 references and 4 characters\n",
            "J complete\n",
            "There are 412 videos for character Z\n",
            "There are 55 json files already made for character Z\n",
            "downloaded videos/Z/Z_08-04-2020_10_13_07.avi\n",
            "Setting mediapipe logger output\n",
            "Running mediapipe on /content/videos/Z/Z_08-04-2020_10_13_07.avi\n",
            "uploaded /content/json/Z/Z_08-04-2020_10_13_07.json\n",
            "downloaded videos/Z/Z_08-25-2020_10_57_58.avi\n",
            "Setting mediapipe logger output\n",
            "Running mediapipe on /content/videos/Z/Z_08-25-2020_10_57_58.avi\n",
            "uploaded /content/json/Z/Z_08-25-2020_10_57_58.json\n",
            "downloaded videos/Z/Z_08-04-2020_10_35_54.avi\n",
            "Setting mediapipe logger output\n",
            "Running mediapipe on /content/videos/Z/Z_08-04-2020_10_35_54.avi\n",
            "uploaded /content/json/Z/Z_08-04-2020_10_35_54.json\n",
            "downloaded videos/Z/Z_08-28-2020_14_43_08.avi\n",
            "Setting mediapipe logger output\n",
            "Running mediapipe on /content/videos/Z/Z_08-28-2020_14_43_08.avi\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}